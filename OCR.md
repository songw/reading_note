传统的 OCR 基于图像处理(二值化、连通域分析、投影分析等)和统计机器学习(Adaboost、SVM)，整体流程如下： 
![[Pasted image 20220924140548.png]]
其中文字行提取的相关步骤(版面分析、行切分)会涉及大量的先验规则，而文字行识别主要基于传统的机器学习方法。随着移动设备的普及，对拍摄图像中的文字提取和识别成为主流需求，同时对场景中文字的识别需求越来越突出。因此，相比于印刷体场景，拍照文字的识别将面临以下三方面挑战：
+ 成像复杂。噪声、模糊、光线变化、形变。
+ 文字复杂。字体、字号、色彩、磨损、笔画宽度任意、方向任意。
+ 场景复杂。版面缺失、背景干扰。
对于上述挑战，传统的 OCR 解决方案存在着以下不足：
+ 通过版面分析（连通域分析）和行切分（投影分析）来生成文本行，要求版面结构有较强的规则性且前背景可分性强（例如黑白文档图像、车牌），无法处理前背景复杂的随意文字（例如场景文字、菜单、广告文字等）。另外，二值化操作本身对图像成像条件和背景要求比较苛刻。
+ 通过人工设计边缘方向特征（例如方向梯度直方图）来训练字符识别模型，在字体变化、模糊或背景干扰时，此类单一的特征的泛化能力迅速下降。
+ 过度依赖于字符切分的结果，在字符扭曲、粘连、噪声干扰的情况下，切分的错误传播尤其突出。
+ 尽管图像预处理模块可有效改善输入图像的质量，但多个独立的校正模块的串联必然带来误差传递。另外由于各模块优化目标独立，它们无法融合到统一的框架中进行。
